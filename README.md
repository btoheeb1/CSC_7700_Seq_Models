# Foundational AI Project 2 - Sequential Language Models

This project implements and compares three sequential language models â€” **RNN**, **LSTM**, and **Transformer** â€” using PyTorch for text generation tasks. The models are trained on subword tokenized data using a **BPE tokenizer (SentencePiece)** and evaluated on **perplexity** and **BLEU score**.

## ğŸ“ Project Structure

```
.
â”œâ”€â”€ dataset.py              # Dataset and collate_fn
â”œâ”€â”€ models.py               # Model definitions (RNN, LSTM, Transformer)
â”œâ”€â”€ tokenizer_utils.py      # Tokenizer training/loading (SentencePiece)
â”œâ”€â”€ training_utils.py       # Training loop, evaluation, BLEU, loss plots
â”œâ”€â”€ main.py                 # Full training + evaluation pipeline
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ train.jsonl         # Training dataset (prompt + completion)
â”‚   â””â”€â”€ test.jsonl          # Testing dataset
â”œâ”€â”€ tokenizer.model         # Saved SentencePiece model (generated)
â”œâ”€â”€ rnn_model.pt            # Trained RNN model weights (generated)
â”œâ”€â”€ lstm_model.pt           # Trained LSTM model weights (generated)
â”œâ”€â”€ transformer_model.pt    # Trained Transformer model weights (generated)
â”œâ”€â”€ generations.txt         # Prompt-based outputs from each model (generated)
â”œâ”€â”€ evaluation_metrics.txt  # Perplexity & BLEU score results (generated)
```

## ğŸš€ How to Run

1. **Install dependencies**
   ```bash
   pip install -r requirements.txt
   ```

2. **Train models and evaluate**
   ```bash
   python main.py
   ```
   This will:
   - Train the tokenizer on `train.jsonl`
   - Train RNN, LSTM, and Transformer models
   - Generate text from prompts
   - Evaluate and save PPL + BLEU metrics

3. **View Outputs**
   - `generations.txt` â†’ generated responses
   - `evaluation_metrics.txt` â†’ PPL and BLEU for all models
   - `*_loss.png` â†’ Training/validation loss curves

## ğŸ§  Prompts Used

- **"Which do you prefer? Dogs or cats?"**
- **"Would you call yourself brave?"**

You can change these in `main.py` to test your own prompts.

## ğŸ“Š Evaluation Metrics

- **Perplexity (PPL)** â€” measures how well the model predicts the next token
- **BLEU Score** â€” evaluates text similarity to the reference

## ğŸ§ª Model Training Details

- Tokenizer: SentencePiece BPE, vocab size 10,000
- Embedding dim: 128
- Hidden dim: 256
- Optimizer: AdamW
- Loss: CrossEntropyLoss
- Epochs: 30 max, with early stopping
- Batch size: 128

## ğŸ“„ License
MIT License

---
Made for CSC 7700 Foundational AI - Project 2

